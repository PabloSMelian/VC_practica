{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6fd4a50",
   "metadata": {},
   "source": [
    "# Process image folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "frank-length",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./faces\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender_model_weights.h5 will be downloaded...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://github.com/serengil/deepface_models/releases/download/v1.0/gender_model_weights.h5\n",
      "To: C:\\Users\\pablo\\.deepface\\weights\\gender_model_weights.h5\n",
      "100%|██████████| 537M/537M [1:20:53<00:00, 111kB/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "race_model_single_batch.h5 will be downloaded...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://github.com/serengil/deepface_models/releases/download/v1.0/race_model_single_batch.h5\n",
      "To: C:\\Users\\pablo\\.deepface\\weights\\race_model_single_batch.h5\n",
      "100%|██████████| 537M/537M [01:27<00:00, 6.11MB/s] \n",
      "Action: emotion: 100%|██████████| 4/4 [00:06<00:00,  1.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "face.jpg\n",
      "[{'age': 31, 'region': {'x': 168, 'y': 206, 'w': 685, 'h': 685}, 'gender': {'Woman': 99.96367692947388, 'Man': 0.03632228763308376}, 'dominant_gender': 'Woman', 'race': {'asian': 99.88231062889099, 'indian': 0.04763609322253615, 'black': 2.1404423478088574e-05, 'white': 0.002086009772028774, 'middle eastern': 4.2716195025604975e-06, 'latino hispanic': 0.06794192595407367}, 'dominant_race': 'asian', 'emotion': {'angry': 5.67243162163944e-09, 'disgust': 1.2498665451463863e-17, 'fear': 4.903072392536956e-09, 'happy': 98.28951358795166, 'sad': 1.6383581158407878e-07, 'surprise': 0.0023081125618773513, 'neutral': 1.7081791535019875}, 'dominant_emotion': 'happy'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 4/4 [00:02<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "face2.jpg\n",
      "[{'age': 33, 'region': {'x': 162, 'y': 215, 'w': 690, 'h': 690}, 'gender': {'Woman': 0.003234537143725902, 'Man': 99.99676942825317}, 'dominant_gender': 'Man', 'race': {'asian': 5.321268693051634e-05, 'indian': 9.24727917248731e-06, 'black': 2.6760568346391016e-07, 'white': 99.95562434725471, 'middle eastern': 0.020072819251268297, 'latino hispanic': 0.024232956660614858}, 'dominant_race': 'white', 'emotion': {'angry': 8.862588884994693e-07, 'disgust': 1.4376012587389436e-11, 'fear': 5.71514791047889e-07, 'happy': 99.99663829803467, 'sad': 1.8166746995618155e-07, 'surprise': 1.985765551992813e-07, 'neutral': 0.003360749178682454}, 'dominant_emotion': 'happy'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 4/4 [00:03<00:00,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happy.jpg\n",
      "[{'age': 33, 'region': {'x': 114, 'y': 92, 'w': 172, 'h': 172}, 'gender': {'Woman': 0.7492891047149897, 'Man': 99.25071597099304}, 'dominant_gender': 'Man', 'race': {'asian': 0.2130748936906457, 'indian': 0.18618995090946555, 'black': 0.013073210720904171, 'white': 67.57243275642395, 'middle eastern': 9.647393226623535, 'latino hispanic': 22.36783653497696}, 'dominant_race': 'white', 'emotion': {'angry': 7.674664376233764e-09, 'disgust': 4.996131608741191e-17, 'fear': 7.288359580911855e-14, 'happy': 99.99966621398926, 'sad': 9.893871746186056e-11, 'surprise': 1.8002054708032844e-09, 'neutral': 0.00033460964914411306}, 'dominant_emotion': 'happy'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from deepface import DeepFace\n",
    "\n",
    "folder = './faces'\n",
    "\n",
    "print(folder)\n",
    "\n",
    "for file_name in os.listdir(folder):\n",
    "    # Asume imágenes en formato png o jpg\n",
    "    if file_name.endswith('.png') or file_name.endswith('.jpg'):\n",
    "        # Procesa la imagen que asume hay cara, no fuerza la detección\n",
    "        obj = DeepFace.analyze(img_path = os.path.join(folder, file_name), enforce_detection=False, actions =['age', 'gender', 'race', 'emotion'])\n",
    "        print(file_name)\n",
    "        print(obj)\n",
    "        #print(obj[\"region\"])\n",
    "        #print(obj[\"age\"])      \n",
    "        #print(obj[\"gender\"])      \n",
    "        #print(obj[\"race\"])       \n",
    "        #print(obj[\"dominant_race\"]) \n",
    "        #print(obj[\"emotion\"])\n",
    "        #print(obj[\"dominant_emotion\"])\n",
    "       \n",
    "        \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "643c68d5",
   "metadata": {},
   "source": [
    "# Detección de características faciales por webcam en tiempo real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 4/4 [00:02<00:00,  1.43it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:02<00:00,  1.49it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:02<00:00,  1.52it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:02<00:00,  1.52it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:02<00:00,  1.55it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:02<00:00,  1.53it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:02<00:00,  1.59it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:02<00:00,  1.63it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:02<00:00,  1.64it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:02<00:00,  1.60it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:02<00:00,  1.54it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:02<00:00,  1.55it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:02<00:00,  1.57it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:02<00:00,  1.60it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:02<00:00,  1.56it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:02<00:00,  1.54it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:02<00:00,  1.41it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:02<00:00,  1.58it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:02<00:00,  1.50it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:02<00:00,  1.51it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:02<00:00,  1.59it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:02<00:00,  1.53it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:02<00:00,  1.47it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:02<00:00,  1.51it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:02<00:00,  1.54it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:02<00:00,  1.62it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:02<00:00,  1.57it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:02<00:00,  1.42it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:02<00:00,  1.47it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:02<00:00,  1.55it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:02<00:00,  1.57it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:02<00:00,  1.55it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:02<00:00,  1.57it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:02<00:00,  1.44it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:02<00:00,  1.52it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:02<00:00,  1.60it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:02<00:00,  1.59it/s]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from deepface import DeepFace\n",
    "\n",
    "vid = cv2.VideoCapture(0)\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "fontScale = 0.4\n",
    "img = cv2.imread(\"./images/windowWithTextRecortada.jpg\")\n",
    "img = cv2.resize(img, (0, 0), None, 0.18, 0.18)\n",
    "height, width, channels = img.shape\n",
    "\n",
    "while True:\n",
    "    ret, frame = vid.read()\n",
    "\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    info = DeepFace.analyze(rgb, actions=['age', 'gender', 'race', 'emotion'], enforce_detection=False)\n",
    "    #info = [\"holaa\"]\n",
    "\n",
    "    if len(info) > 0:\n",
    "        face = info[0]\n",
    "\n",
    "        age = face['age']\n",
    "        emotion = face['dominant_emotion']\n",
    "        race = face['dominant_race']\n",
    "        gender = face['dominant_gender']\n",
    "        #age = 25\n",
    "        #emotion = \"happy\"\n",
    "        #race = \"black\"\n",
    "        #gender = \"male\"\n",
    "\n",
    "        frame[10:height + 10, 10:width + 10] = img\n",
    "\n",
    "        cv2.putText(frame, str(age), (60, 40), font, fontScale, (0, 0, 0), 2)\n",
    "        cv2.putText(frame, str(gender), (60, 61), font, fontScale, (0, 0, 0), 2)\n",
    "        cv2.putText(frame, str(race), (60, 83), font, fontScale, (0, 0, 0), 2)\n",
    "        cv2.putText(frame, str(emotion), (60, 104), font, fontScale, (0, 0, 0), 2)\n",
    "\n",
    "    cv2.imshow('Vid', frame)\n",
    "\n",
    "    if cv2.waitKey(20) == 27:\n",
    "        break\n",
    "\n",
    "vid.release()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detección de características faciales de un archivo de vídeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 4/4 [00:02<00:00,  1.38it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:02<00:00,  1.74it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:02<00:00,  1.78it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:02<00:00,  1.76it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:02<00:00,  1.72it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:02<00:00,  1.70it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:02<00:00,  1.64it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:02<00:00,  1.68it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:02<00:00,  1.64it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:02<00:00,  1.64it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:02<00:00,  1.58it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:02<00:00,  1.61it/s]\n",
      "Action: emotion: 100%|██████████| 4/4 [00:02<00:00,  1.63it/s]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from deepface import DeepFace\n",
    "\n",
    "vid = cv2.VideoCapture(\"./video.mp4\")\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "fontScale = 0.4\n",
    "img = cv2.imread(\"./images/windowWithTextRecortada.jpg\")\n",
    "img = cv2.resize(img, (0, 0), None, 0.18, 0.18)\n",
    "height, width, channels = img.shape\n",
    "\n",
    "while True:\n",
    "    ret, frame = vid.read()\n",
    "\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    info = DeepFace.analyze(rgb, actions=['age', 'gender', 'race', 'emotion'], enforce_detection=False)\n",
    "    #info = [\"holaa\"]\n",
    "\n",
    "    if len(info) > 0:\n",
    "        face = info[0]\n",
    "\n",
    "        age = face['age']\n",
    "        emotion = face['dominant_emotion']\n",
    "        race = face['dominant_race']\n",
    "        gender = face['dominant_gender']\n",
    "        #age = 25\n",
    "        #emotion = \"happy\"\n",
    "        #race = \"black\"\n",
    "        #gender = \"male\"\n",
    "\n",
    "        frame[10:height + 10, 10:width + 10] = img\n",
    "\n",
    "        cv2.putText(frame, str(age), (60, 40), font, fontScale, (0, 0, 0), 2)\n",
    "        cv2.putText(frame, str(gender), (60, 61), font, fontScale, (0, 0, 0), 2)\n",
    "        cv2.putText(frame, str(race), (60, 83), font, fontScale, (0, 0, 0), 2)\n",
    "        cv2.putText(frame, str(emotion), (60, 104), font, fontScale, (0, 0, 0), 2)\n",
    "\n",
    "    cv2.imshow('Vid', frame)\n",
    "\n",
    "    if cv2.waitKey(20) == 27:\n",
    "        break\n",
    "\n",
    "vid.release()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('deepface')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "12028effb1af0cd2244438ff9b17d06bb1d7695ec7a554a144e43ec4b8b79006"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
